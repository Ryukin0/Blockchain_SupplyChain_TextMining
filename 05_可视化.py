import os
import pandas as pd
from collections import Counter
import matplotlib.pyplot as plt
from wordcloud import WordCloud
from tqdm import tqdm
import jieba

# ========== è·¯å¾„é…ç½® ==========
YEAR = 2018
BASE_DIR = "/Users/qqqqq/Desktop/ppppp/å¹´æŠ¥"
TXT_DIR = os.path.join(BASE_DIR, f"å¹´æŠ¥TXT_{YEAR}")
OUTPUT_DIR = os.path.join(BASE_DIR, f"åˆ†æç»“æœ_{YEAR}")
os.makedirs(OUTPUT_DIR, exist_ok=True)

# ========== è‡ªå®šä¹‰å…³é”®è¯ä½“ç³» ==========
keyword_groups = {
    "åŒºå—é“¾ç›¸å…³": [
        "åŒºå—é“¾", "åˆ†å¸ƒå¼è´¦æœ¬", "æ™ºèƒ½åˆçº¦", "å»ä¸­å¿ƒåŒ–", "è”ç›Ÿé“¾", "å…¬æœ‰é“¾", "ç§æœ‰é“¾",
        "ä¸Šé“¾", "é“¾ä¸Š", "é“¾æ”¹", "é“¾ç«¯", "é“¾æ¡æ•°æ®", "åŠ å¯†å­˜è¯", "ç”µå­å­˜è¯",
        "æº¯æºç³»ç»Ÿ", "æ•°å­—å‡­è¯", "æ•°æ®ç¡®æƒ", "å¯ä¿¡è®¡ç®—", "åŠ å¯†ç®—æ³•", "é“¾ä¸Šæ•°æ®", "æ•°æ®å…±äº«å¹³å°"
    ],
    "æ•°å­—åŒ–è½¬å‹": [
        "æ•°å­—åŒ–", "æ•°æ™ºåŒ–", "ä¿¡æ¯åŒ–", "æ™ºèƒ½åŒ–", "å¤§æ•°æ®", "äº‘è®¡ç®—", "äººå·¥æ™ºèƒ½", "ç‰©è”ç½‘", "æ•°å­—å¹³å°"
    ],
    "ä¾›åº”é“¾æ²»ç†": [
        "ä¾›åº”é“¾", "ä¸Šæ¸¸", "ä¸‹æ¸¸", "ä¾›åº”å•†", "ç‰©æµ", "ååŒ", "é“¾æ¡", "æº¯æº", "äº§ä¸šé“¾", "é“¾ä¸»ä¼ä¸š"
    ],
    "ä¿¡ç”¨ä¸ä¿¡ä»»": [
        "ä¿¡ç”¨", "ä¿¡ä»»", "ä¿¡èª‰", "åˆè§„", "é€æ˜", "å¯ä¿¡", "ä¿¡ç”¨ä½“ç³»", "ä¿¡ç”¨ç®¡ç†", "é£é™©æ§åˆ¶", 
        "éªŒè¯", "å…±äº«", "å®‰å…¨"
    ]
}

# æ‰å¹³åŒ–å…³é”®è¯åˆ—è¡¨
keywords = [w for group in keyword_groups.values() for w in group]

# ========== è¯»å–å¹¶ç»Ÿè®¡ ==========
all_counts = Counter()

txt_files = [f for f in os.listdir(TXT_DIR) if f.endswith(".txt")]
for txt_file in tqdm(txt_files, desc=f"ç»Ÿè®¡å…³é”®è¯ ({YEAR})"):
    txt_path = os.path.join(TXT_DIR, txt_file)
    try:
        with open(txt_path, "r", encoding="utf-8") as f:
            text = f.read()
        words = jieba.lcut(text)
        word_count = Counter(words)
        for kw in keywords:
            all_counts[kw] += word_count[kw]
    except Exception as e:
        print(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥: {txt_file}, é”™è¯¯: {e}")

# ========== æ ‡å‡†åŒ–ï¼ˆå½’ä¸€åŒ–ï¼‰ ==========
total = sum(all_counts.values())
norm_freq = {k: v / total for k, v in all_counts.items()}

# è½¬æ¢ä¸º DataFrame
df = pd.DataFrame({
    "å…³é”®è¯": list(norm_freq.keys()),
    "æ ‡å‡†åŒ–é¢‘ç‡": list(norm_freq.values()),
    "åŸå§‹è®¡æ•°": [all_counts[k] for k in norm_freq.keys()]
}).sort_values(by="æ ‡å‡†åŒ–é¢‘ç‡", ascending=False)

# ä¿å­˜ç»“æœ
df.to_excel(os.path.join(OUTPUT_DIR, f"è¯é¢‘ç»Ÿè®¡_{YEAR}.xlsx"), index=False)

# ===== ä¸­æ–‡å­—ä½“æ”¯æŒï¼ˆMac / Windowséƒ½é€‚ç”¨ï¼‰=====
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['font.sans-serif'] = ['Heiti TC', 'SimHei']  # Macç”¨Heitiï¼ŒWinç”¨SimHei

# ========== å¯è§†åŒ–1ï¼šå…³é”®è¯æŸ±çŠ¶å›¾ ==========
words = df["å…³é”®è¯"]
freqs = df["åŸå§‹è®¡æ•°"]

plt.figure(figsize=(12, 7))
# å¦‚æœå…³é”®è¯é‡Œå«â€œé“¾â€ï¼Œé«˜äº®ä¸ºæ©™è‰²ï¼Œå¦åˆ™ä¸ºè“è‰²
colors = ["#E24A33" if "é“¾" in w else "#4A90E2" for w in words]
bars = plt.bar(words, freqs, color=colors, edgecolor="black", alpha=0.85)

plt.title(f"ä¼ä¸šå¹´æŠ¥é«˜é¢‘è¯ç»Ÿè®¡ï¼ˆ{YEAR}å¹´åº¦ï¼‰\nåŒºå—é“¾ç›¸å…³è¯æ±‡é«˜äº®æ˜¾ç¤º", fontsize=18, fontweight="bold", pad=20)
plt.xlabel("å…³é”®è¯", fontsize=14)
plt.ylabel("å‡ºç°æ¬¡æ•°", fontsize=14)
plt.xticks(rotation=45, ha='right', fontsize=12)
plt.yticks(fontsize=12)
plt.grid(axis='y', linestyle='--', alpha=0.5)

for bar in bars:
    plt.text(bar.get_x() + bar.get_width()/2,
             bar.get_height() + 1,
             f"{int(bar.get_height())}",
             ha='center', va='bottom', fontsize=10)

plt.tight_layout()
plt.savefig(os.path.join(OUTPUT_DIR, f"è¯é¢‘ç»Ÿè®¡_{YEAR}.png"), dpi=300, bbox_inches='tight')
plt.show()

# ========== å¯è§†åŒ–2ï¼šè¯äº‘ ==========
wc = WordCloud(
    font_path="/System/Library/Fonts/STHeiti Medium.ttc",
    width=800, height=600,
    background_color="white",
    colormap="viridis"
)
wc.generate_from_frequencies(all_counts)
wc.to_file(os.path.join(OUTPUT_DIR, f"è¯äº‘_{YEAR}.png"))

print(f"âœ… {YEAR} å¹´å…³é”®è¯åˆ†æå®Œæˆï¼")
print(f"ğŸ“Š ç»“æœä¿å­˜è·¯å¾„: {OUTPUT_DIR}")

# ========== å¯è§†åŒ–3ï¼šå¯ä¿¡åº¦æŒ‡æ•°åˆ†å¸ƒ ==========
trust_path = os.path.join(OUTPUT_DIR, f"æ•°æ®å¯ä¿¡åº¦æŒ‡æ•°_{YEAR}.xlsx")

if os.path.exists(trust_path):
    trust_df = pd.read_excel(trust_path)

    # è¿‡æ»¤å¼‚å¸¸å€¼
    trust_df = trust_df[trust_df["Trust_Index"] >= 0]
    plt.figure(figsize=(10, 6))
    plt.hist(trust_df["Trust_Index"], bins=30, color="#6EC6CA", edgecolor="black", alpha=0.8)
    plt.title(f"{YEAR} å¹´ä¼ä¸šå¹´æŠ¥â€œæ•°æ®å¯ä¿¡åº¦æŒ‡æ•°â€åˆ†å¸ƒ", fontsize=18, fontweight="bold", pad=20)
    plt.xlabel("Trust_Indexï¼ˆå¯ä¿¡åº¦æŒ‡æ•°ï¼‰", fontsize=14)
    plt.ylabel("ä¼ä¸šæ•°é‡", fontsize=14)
    plt.grid(axis='y', linestyle='--', alpha=0.5)
    plt.tight_layout()
    plt.savefig(os.path.join(OUTPUT_DIR, f"å¯ä¿¡åº¦æŒ‡æ•°åˆ†å¸ƒ_{YEAR}.png"), dpi=300, bbox_inches='tight')
    plt.show()

    # ========== å¯è§†åŒ–4ï¼šå¯ä¿¡åº¦å‰20ä¼ä¸š ==========
    top20 = trust_df.sort_values(by="Trust_Index", ascending=False).head(20)
    plt.figure(figsize=(12, 8))
    bars = plt.barh(top20["å…¬å¸ç®€ç§°"], top20["Trust_Index"], color="#FFB74D", alpha=0.85)
    plt.gca().invert_yaxis()  # è®©æ’åç¬¬ä¸€åœ¨æœ€ä¸Šæ–¹
    plt.title(f"{YEAR} å¹´â€œå¯ä¿¡åº¦æŒ‡æ•°â€æœ€é«˜çš„20å®¶ä¼ä¸š", fontsize=18, fontweight="bold", pad=20)
    plt.xlabel("Trust_Index", fontsize=14)
    plt.ylabel("å…¬å¸ç®€ç§°", fontsize=14)
    for bar in bars:
        plt.text(bar.get_width() + 0.0005,
                 bar.get_y() + bar.get_height()/2,
                 f"{bar.get_width():.4f}",
                 va='center', fontsize=10)
    plt.tight_layout()
    plt.savefig(os.path.join(OUTPUT_DIR, f"å¯ä¿¡åº¦å‰20ä¼ä¸š_{YEAR}.png"), dpi=300, bbox_inches='tight')
    plt.show()

    print(f"âœ… å¯ä¿¡åº¦æŒ‡æ•°åˆ†å¸ƒä¸Top20å›¾å·²ç”Ÿæˆï¼")
else:
    print(f"âš ï¸ æœªæ‰¾åˆ° {trust_path}ï¼Œè·³è¿‡å¯ä¿¡åº¦å¯è§†åŒ–ã€‚")
