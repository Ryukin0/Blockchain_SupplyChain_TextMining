import os
import requests
import pandas as pd
import time
from pathlib import Path

# ========== åŸºæœ¬å‚æ•° ==========
YEAR = 2023  # æŒ‰ç…§å¹´ä»½è¿›è¡Œé“¾æ¥æŠ“å–ï¼Œæ­¤å¤„å¯è¾“å…¥2018-2026
SAVE_FOLDER = Path.home() / "Desktop" / "å¹´æŠ¥é“¾æ¥è·å–"
SAVE_FOLDER.mkdir(exist_ok=True)
FINAL_PATH = SAVE_FOLDER / f"{YEAR}_å¹´æŠ¥é“¾æ¥.xlsx"

ANNOUNCE_URL = "http://www.cninfo.com.cn/new/hisAnnouncement/query"
COMPANY_INFO_URL = "http://www.cninfo.com.cn/new/data/companyList.json"

headers = {
    'User-Agent': 'Mozilla/5.0',
    'Referer': 'http://www.cninfo.com.cn/',
    'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8'
}

# ========== è·å–å…¬å¸ä¿¡æ¯ ==========
def get_company_info():
    print("æ­£åœ¨åŠ è½½ä¸Šå¸‚å…¬å¸è¡Œä¸šä¿¡æ¯ï¼ˆæ–°ç‰ˆæ¥å£ï¼‰...")
    url = "http://www.cninfo.com.cn/new/data/companyList.json"
    res = requests.get(url, headers=headers)
    try:
        data = res.json()
    except Exception as e:
        print("âŒ è¿”å›æ•°æ®ä¸æ˜¯JSON:", e)
        return pd.DataFrame(columns=["å…¬å¸ä»£ç ", "å…¬å¸ç®€ç§°", "è¡Œä¸š"])

    df_list = []
    company_blocks = data.get("companyList", [])
    for block in company_blocks:
        if isinstance(block, dict) and "stockList" in block:
            sub_list = block["stockList"]
            if isinstance(sub_list, list) and len(sub_list) > 0:
                df = pd.DataFrame(sub_list)
                df_list.append(df)
    if not df_list:
        print("âš ï¸ æœªä»æ¥å£è·å–åˆ°å…¬å¸ä¿¡æ¯ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–æ¥å£ç»“æ„ã€‚")
        return pd.DataFrame(columns=["å…¬å¸ä»£ç ", "å…¬å¸ç®€ç§°", "è¡Œä¸š"])

    all_info = pd.concat(df_list, ignore_index=True)
    rename_map = {}
    for col in all_info.columns:
        if "code" in col.lower(): rename_map[col] = "å…¬å¸ä»£ç "
        if "zwjc" in col.lower() or "ç®€ç§°" in col: rename_map[col] = "å…¬å¸ç®€ç§°"
        if "industry" in col.lower(): rename_map[col] = "è¡Œä¸š"
    all_info = all_info.rename(columns=rename_map)

    all_info["å…¬å¸ä»£ç "] = all_info["å…¬å¸ä»£ç "].astype(str)
    print(f"âœ… å…±åŠ è½½ {len(all_info)} å®¶ä¸Šå¸‚å…¬å¸ã€‚")
    return all_info[["å…¬å¸ä»£ç ", "å…¬å¸ç®€ç§°", "è¡Œä¸š"]]

# ========== è·å–å¹´æŠ¥å‡½æ•°ï¼ˆæ–­ç‚¹ç»­é‡‡ï¼‰ ==========
def get_annual_reports(plate, company_info):
    print(f"\nğŸ“¦ å¼€å§‹é‡‡é›† {plate} æ¿å— {YEAR} å¹´å¹´æŠ¥ä¿¡æ¯...")

    temp_path = SAVE_FOLDER / f"temp_{plate}_{YEAR}.csv"
    all_data = []

    # å¦‚æœå­˜åœ¨ä¸´æ—¶æ–‡ä»¶ï¼Œåˆ™ä»ä¸Šæ¬¡è¿›åº¦ç»§ç»­
    start_page = 1
    if temp_path.exists():
        df_temp = pd.read_csv(temp_path)
        all_data = df_temp.to_dict('records')
        start_page = (len(all_data) // 30) + 1
        print(f"ğŸ” æ£€æµ‹åˆ°æ–­ç‚¹ï¼Œç»­é‡‡ç¬¬ {start_page} é¡µï¼ˆå·²é‡‡ {len(all_data)} æ¡ï¼‰")

    params = {
        'stock': '',
        'tabName': 'fulltext',
        'plate': plate,
        'category': 'category_ndbg_szsh',
        'seDate': f'{YEAR}-01-01~{YEAR}-12-31',
        'pageNum': 1,
        'pageSize': 30,
        'column': 'szse',
    }

    MAX_PAGES = 100
    for page in range(start_page, MAX_PAGES + 1):
        params['pageNum'] = page
        try:
            res = requests.post(ANNOUNCE_URL, data=params, headers=headers, timeout=15)
            if res.status_code != 200:
                print(f"âš ï¸ ç¬¬{page}é¡µè¯·æ±‚å¼‚å¸¸ï¼ŒçŠ¶æ€ç  {res.status_code}")
                break

            json_data = res.json()
            if not isinstance(json_data, dict) or "announcements" not in json_data:
                print(f"âš ï¸ ç¬¬{page}é¡µè¿”å›ç©ºæˆ–ç»“æ„å¼‚å¸¸ï¼Œé€€å‡ºå¾ªç¯ã€‚")
                break

            announcements = json_data.get("announcements", [])
            if not announcements:
                print(f"âœ… ç¬¬{page}é¡µä¸ºç©ºï¼Œè¯´æ˜è¯¥æ¿å—å·²é‡‡å®Œã€‚")
                break

            for ann in announcements:
                title = ann.get('announcementTitle', '')
                if any(x in title for x in ['æ‘˜è¦', 'è‹±æ–‡ç‰ˆ', 'å…¬å‘Š', 'æç¤º', 'è¡¥å……', 'æ›´æ­£']):
                    continue
                if 'ST' in ann.get('secName', ''):
                    continue
                record = {
                    'å…¬å¸ä»£ç ': ann.get('secCode'),
                    'å…¬å¸ç®€ç§°': ann.get('secName'),
                    'å…¬å‘Šæ ‡é¢˜': title,
                    'å…¬å‘Šæ—¥æœŸ': ann.get('announcementTime'),
                    'PDFé“¾æ¥': 'http://static.cninfo.com.cn/' + ann.get('adjunctUrl', '')
                }
                all_data.append(record)

            # æ¯ 10 é¡µä¿å­˜ä¸€æ¬¡è¿›åº¦
            if page % 10 == 0:
                pd.DataFrame(all_data).to_csv(temp_path, index=False)
                print(f"ğŸ’¾ å·²ä¿å­˜ä¸­é—´ç»“æœï¼ˆç¬¬ {page} é¡µï¼‰")

            print(f"â†’ å·²è·å–ç¬¬ {page} é¡µï¼Œå…± {len(all_data)} æ¡")
            time.sleep(0.8)

        except requests.exceptions.Timeout:
            print(f"â³ ç¬¬{page}é¡µè¯·æ±‚è¶…æ—¶ï¼Œè·³è¿‡ã€‚")
            continue
        except Exception as e:
            print(f"âŒ ç¬¬{page}é¡µå‡ºé”™: {e}")
            time.sleep(2)
            continue

    df = pd.DataFrame(all_data)
    if not df.empty:
        df = df.merge(company_info, on=["å…¬å¸ä»£ç ", "å…¬å¸ç®€ç§°"], how="left")
        df = df[~df["è¡Œä¸š"].isin(["æˆ¿åœ°äº§ä¸š", "é‡‘èä¸š"])]
    return df

# ========== ä¸»ç¨‹åº ==========
if __name__ == "__main__":
    company_info = get_company_info()
    plates = ["szse", "sse", "bj"]  # æ·±å¸‚ã€æ²ªå¸‚ã€åŒ—äº¤æ‰€
    final_df_list = []

    for p in plates:
        df_plate = get_annual_reports(p, company_info)
        if not df_plate.empty:
            final_df_list.append(df_plate)
        time.sleep(2)

    if final_df_list:
        final_df = pd.concat(final_df_list, ignore_index=True)
        final_df.to_excel(FINAL_PATH, index=False)
        print(f"\nâœ… å·²ä¿å­˜æœ€ç»ˆæ–‡ä»¶: {FINAL_PATH}")
        print(f"å…±é‡‡é›† {len(final_df)} æ¡ç¬¦åˆæ¡ä»¶çš„å¹´æŠ¥é“¾æ¥ã€‚")
    else:
        print("âš ï¸ æœªé‡‡é›†åˆ°ä»»ä½•æ•°æ®ï¼Œè¯·æ£€æŸ¥æ¥å£ç»“æ„æˆ–ç½‘ç»œã€‚")
